{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Imbalanced Data Classification\n",
    "\n",
    "## Reference\n",
    "\n",
    "* 机器学习之类别不平衡问题 (3) —— 采样方法: https://www.cnblogs.com/massquantity/p/9382710.html\n",
    "* 不平衡数据集的处理: https://www.cnblogs.com/kamekin/p/9824294.html\n",
    "* imblearn document: https://imbalanced-learn.org/stable/index.html\n",
    "* https://books.google.com.ph/books?id=GvKrDwAAQBAJ&pg=PA452&lpg=PA452&dq=smote+SMOTEENN&source=bl&ots=uD6yhIQ_cZ&sig=ACfU3U01CuiKc1bOPmQgsOdaMUekdiozRA&hl=en&sa=X&ved=2ahUKEwiEsIL_mt3pAhXoy4sBHfVDC38Q6AEwD3oECAoQAg#v=onepage&q=smote%20SMOTEENN&f=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Imbalanced learn\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier \n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Outliers detection\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-class Datasets\n",
    "\n",
    "`v_train.csv` and `p_train.csv` are data sets with binary classes (e.g., positive, negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SMOTE on `v_train.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv = pd.read_csv(\"v/v_train.csv\", names=[0,1,2,3,4,5,6,7,8,9,'label'])\n",
    "#Xv.label.loc[Xv.label==' negative'] = 0\n",
    "#Xv.label.loc[Xv.label==' positive'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xv.iloc[:,0:10]\n",
    "y = Xv.iloc[:, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE\n",
      "Counter({' negative': 867, ' positive': 88})\n",
      "After SMOTE\n",
      "Counter({' positive': 867, ' negative': 867})\n",
      "Random Forest evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93       161\n",
      "    positive       0.93      0.95      0.94       186\n",
      "\n",
      "    accuracy                           0.94       347\n",
      "   macro avg       0.94      0.94      0.94       347\n",
      "weighted avg       0.94      0.94      0.94       347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before SMOTE\")\n",
    "print(Counter(Xv.label))\n",
    "\n",
    "smote = SMOTE(random_state=0) \n",
    "\n",
    "X_smote, y_smote = smote.fit_sample(X, y)\n",
    "\n",
    "print(\"After SMOTE\")\n",
    "print(Counter(y_smote))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_smote, y_smote, test_size=0.2)\n",
    "\n",
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=5, random_state=0, max_depth=2)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val) # do predict on validation set\n",
    "print(\"Random Forest evalute on validation set\")\n",
    "print(classification_report(y_val, y_pred)) # Show the evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on testing set\n",
    "Xv_test = pd.read_csv(\"v/v_test.csv\")\n",
    "X_test = Xv_test.iloc[:,:10]\n",
    "pred = rf.predict(Xv_test.iloc[:, :10])\n",
    "Xv_test['label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV file\n",
    "Xv_test.to_csv(\"v_test_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SMOTEENN on `p_train.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = pd.read_csv(\"p/p_train.csv\", names=[0,1,2,3,4,5,6,7,'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xp.iloc[:,0:8]\n",
    "y = Xp.iloc[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTEENN\n",
      "Counter({' negative': 484, ' positive': 261})\n",
      "After SMOTEENN\n",
      "Counter({' positive': 266, ' negative': 213})\n",
      "Random Forest evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.88        41\n",
      "    positive       0.89      0.93      0.91        55\n",
      "\n",
      "    accuracy                           0.90        96\n",
      "   macro avg       0.90      0.89      0.89        96\n",
      "weighted avg       0.90      0.90      0.90        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before SMOTEENN\")\n",
    "print(Counter(Xp.label))\n",
    "\n",
    "sme = SMOTEENN(random_state=27)\n",
    "X_sme, y_sme = sme.fit_resample(X, y)\n",
    "\n",
    "print(\"After SMOTEENN\")\n",
    "print(Counter(y_sme))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_sme, y_sme, test_size=0.2)\n",
    "\n",
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=5, random_state=0, max_depth=2)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val) # do predict on validation set\n",
    "print(\"Random Forest evalute on validation set\")\n",
    "print(classification_report(y_val, y_pred)) # Show the evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on testing set\n",
    "Xp_test = pd.read_csv(\"p/p_test.csv\")\n",
    "X_test = Xp_test.iloc[:,:8]\n",
    "pred = rf.predict(Xp_test.iloc[:,:8])\n",
    "Xp_test['label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV file\n",
    "Xp_test.to_csv(\"p_test_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Datasets\n",
    "\n",
    "`y_train.csv`, `e_train.csv` and `a_train.csv` are datasets with multi-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_random_forest(X, y, n=15, depth=2, state=0, divide=0.2):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=divide)\n",
    "\n",
    "    # Balanced Random Forest Model\n",
    "    brf = BalancedRandomForestClassifier(n_estimators=n, max_depth=depth, random_state=state)\n",
    "    brf.fit(X_train, y_train)\n",
    "    y_pred = brf.predict(X_val) # do predict on validation set\n",
    "    print(\"Balanced Random Forest evalute on validation set\")\n",
    "    print(classification_report(y_val, y_pred)) # Show the evaluation result\n",
    "    \n",
    "    return brf\n",
    "\n",
    "def rus_boost(X, y, n=50, lr=1e-3, state=0, divide=0.2):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=divide)\n",
    "\n",
    "    # Random Forest Model\n",
    "    rusb = RUSBoostClassifier(n_estimators=n, learning_rate=lr, random_state=state)\n",
    "    rusb.fit(X_train, y_train)\n",
    "    y_pred = rusb.predict(X_val) # do predict on validation set\n",
    "    print(\"RUSBoost Classifier evalute on validation set\")\n",
    "    print(classification_report(y_val, y_pred)) # Show the evaluation result\n",
    "    \n",
    "    return rusb\n",
    "\n",
    "def easy_ensemble(X, y, n=10, state=0, divide=0.2):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=divide)\n",
    "\n",
    "    # Random Forest Model\n",
    "    eec = EasyEnsembleClassifier(n_estimators=n, random_state=state)\n",
    "    eec.fit(X_train, y_train)\n",
    "    y_pred = eec.predict(X_val) # do predict on validation set\n",
    "    print(\"Easy Ensemble Classifier evalute on validation set\")\n",
    "    print(classification_report(y_val, y_pred)) # Show the evaluation result\n",
    "    \n",
    "    return eec\n",
    "\n",
    "def balanced_bagging(X, y, n=10, state=0, divide=0.2):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=divide)\n",
    "\n",
    "    # Random Forest Model\n",
    "    bbc = BalancedBaggingClassifier(n_estimators=n, random_state=state)\n",
    "    bbc.fit(X_train, y_train)\n",
    "    y_pred = bbc.predict(X_val) # do predict on validation set\n",
    "    print(\"Balanced Bagging Classifier evalute on validation set\")\n",
    "    print(classification_report(y_val, y_pred)) # Show the evaluation result\n",
    "    \n",
    "    return bbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `y_train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'MIT': 234,\n",
       "         'NUC': 410,\n",
       "         'CYT': 450,\n",
       "         'ME1': 36,\n",
       "         'EXC': 33,\n",
       "         'ME2': 46,\n",
       "         'ME3': 140,\n",
       "         'VAC': 30,\n",
       "         'POX': 18,\n",
       "         'ERL': 5})"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy = pd.read_csv(\"y/y_train.csv\", names=[0,1,2,3,4,5,6,7,'label'])\n",
    "Counter(Xy.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.iloc[:,0:8]\n",
    "y = Xy.iloc[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CYT       0.49      0.57      0.53       109\n",
      "         ERL       0.50      1.00      0.67         2\n",
      "         EXC       0.33      0.57      0.42         7\n",
      "         ME1       0.50      0.44      0.47         9\n",
      "         ME2       0.21      0.33      0.26         9\n",
      "         ME3       0.44      0.84      0.58        25\n",
      "         MIT       0.47      0.16      0.24        44\n",
      "         NUC       0.42      0.12      0.18        68\n",
      "         POX       0.14      0.75      0.24         4\n",
      "         VAC       0.08      0.25      0.12         4\n",
      "\n",
      "    accuracy                           0.41       281\n",
      "   macro avg       0.36      0.50      0.37       281\n",
      "weighted avg       0.44      0.41      0.38       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brf = balanced_random_forest(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSBoost Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CYT       0.44      0.35      0.39        88\n",
      "         ERL       0.50      1.00      0.67         1\n",
      "         EXC       0.42      0.56      0.48         9\n",
      "         ME1       0.50      0.50      0.50         8\n",
      "         ME2       0.00      0.00      0.00         6\n",
      "         ME3       0.76      0.76      0.76        29\n",
      "         MIT       0.31      0.42      0.36        43\n",
      "         NUC       0.59      0.39      0.47        89\n",
      "         POX       0.67      0.40      0.50         5\n",
      "         VAC       0.03      0.33      0.05         3\n",
      "\n",
      "    accuracy                           0.42       281\n",
      "   macro avg       0.42      0.47      0.42       281\n",
      "weighted avg       0.49      0.42      0.45       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusb = rus_boost(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy Ensemble Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CYT       0.55      0.43      0.48        92\n",
      "         ERL       0.33      1.00      0.50         1\n",
      "         EXC       0.42      1.00      0.59         5\n",
      "         ME1       0.25      0.33      0.29         3\n",
      "         ME2       0.43      0.50      0.46        12\n",
      "         ME3       0.68      0.62      0.65        24\n",
      "         MIT       0.40      0.44      0.42        54\n",
      "         NUC       0.61      0.32      0.42        79\n",
      "         POX       0.33      0.17      0.22         6\n",
      "         VAC       0.02      0.20      0.04         5\n",
      "\n",
      "    accuracy                           0.42       281\n",
      "   macro avg       0.40      0.50      0.41       281\n",
      "weighted avg       0.52      0.42      0.45       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec = easy_ensemble(X, y, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Bagging Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CYT       0.44      0.36      0.40        83\n",
      "         ERL       0.67      1.00      0.80         2\n",
      "         EXC       0.41      0.70      0.52        10\n",
      "         ME1       0.62      0.83      0.71         6\n",
      "         ME2       0.17      0.38      0.23         8\n",
      "         ME3       0.68      0.83      0.75        30\n",
      "         MIT       0.59      0.47      0.52        47\n",
      "         NUC       0.47      0.29      0.36        82\n",
      "         POX       0.20      0.75      0.32         4\n",
      "         VAC       0.04      0.11      0.06         9\n",
      "\n",
      "    accuracy                           0.43       281\n",
      "   macro avg       0.43      0.57      0.47       281\n",
      "weighted avg       0.48      0.43      0.44       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bbc = balanced_bagging(X, y, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RUSBoost Classifier to predect on testing set\n",
    "Xy_test = pd.read_csv(\"y/y_test.csv\")\n",
    "X_test = Xy_test.iloc[:,:8]\n",
    "pred = rusb.predict(Xy_test.iloc[:,:8])\n",
    "Xy_test['label'] = pred\n",
    "\n",
    "# Save\n",
    "Xy_test.to_csv(\"y_test_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `e_train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'cp': 143,\n",
       "         'im': 77,\n",
       "         'imS': 2,\n",
       "         'imL': 2,\n",
       "         'imU': 35,\n",
       "         'om': 20,\n",
       "         'omL': 5,\n",
       "         'pp': 19})"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xe = pd.read_csv(\"e/e_train.csv\", names=[0,1,2,3,4,5,6,'label'])\n",
    "Counter(Xe.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xe.iloc[:,0:7]\n",
    "y = Xe.iloc[:, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       1.00      0.14      0.25        76\n",
      "          im       0.82      0.84      0.83        38\n",
      "         imL       0.00      0.00      0.00         0\n",
      "         imS       0.00      0.00      0.00         1\n",
      "         imU       0.75      0.35      0.48        17\n",
      "          om       0.36      1.00      0.53         8\n",
      "         omL       0.00      0.00      0.00         4\n",
      "          pp       0.06      0.50      0.11         8\n",
      "\n",
      "    accuracy                           0.40       152\n",
      "   macro avg       0.37      0.35      0.28       152\n",
      "weighted avg       0.81      0.40      0.42       152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\envs\\pytorch15\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "brf = balanced_random_forest(X, y, n=20, depth=2, state=9, divide=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSBoost Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       0.66      0.95      0.78        22\n",
      "          im       1.00      0.11      0.19        19\n",
      "         imL       0.00      0.00      0.00         0\n",
      "         imS       0.07      1.00      0.12         1\n",
      "         imU       0.50      0.12      0.20         8\n",
      "          om       1.00      0.20      0.33         5\n",
      "         omL       1.00      1.00      1.00         1\n",
      "          pp       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.52        61\n",
      "   macro avg       0.62      0.55      0.43        61\n",
      "weighted avg       0.77      0.52      0.48        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\envs\\pytorch15\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rusb = rus_boost(X, y, n=50, lr=1e-2, state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy Ensemble Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       0.96      0.77      0.85        30\n",
      "          im       0.57      0.53      0.55        15\n",
      "         imL       0.00      0.00      0.00         0\n",
      "         imS       0.00      0.00      0.00         0\n",
      "         imU       0.12      0.10      0.11        10\n",
      "          om       0.25      0.50      0.33         2\n",
      "         omL       1.00      0.50      0.67         2\n",
      "          pp       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.56        61\n",
      "   macro avg       0.36      0.30      0.31        61\n",
      "weighted avg       0.67      0.56      0.61        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\envs\\pytorch15\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "eec = easy_ensemble(X, y, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Bagging Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cp       0.88      0.96      0.92        23\n",
      "          im       1.00      0.41      0.58        22\n",
      "         imL       0.00      0.00      0.00         1\n",
      "         imS       0.25      1.00      0.40         1\n",
      "         imU       0.40      0.50      0.44         4\n",
      "          om       1.00      0.75      0.86         4\n",
      "         omL       0.50      1.00      0.67         1\n",
      "          pp       0.50      1.00      0.67         5\n",
      "\n",
      "    accuracy                           0.70        61\n",
      "   macro avg       0.57      0.70      0.57        61\n",
      "weighted avg       0.84      0.70      0.71        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bbc = balanced_bagging(X, y, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Balanced Bagging Classifier to predict on testing set\n",
    "Xe_test = pd.read_csv(\"e/e_test.csv\")\n",
    "X_test = Xe_test.iloc[:,:7]\n",
    "pred = bbc.predict(Xe_test.iloc[:,:7])\n",
    "Xe_test['label'] = pred\n",
    "\n",
    "# Save\n",
    "Xe_test.to_csv(\"e_test_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `a_train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({15: 103,\n",
       "         7: 383,\n",
       "         9: 669,\n",
       "         10: 617,\n",
       "         8: 553,\n",
       "         20: 26,\n",
       "         16: 67,\n",
       "         19: 32,\n",
       "         14: 126,\n",
       "         11: 464,\n",
       "         12: 264,\n",
       "         18: 42,\n",
       "         13: 200,\n",
       "         5: 115,\n",
       "         4: 56,\n",
       "         6: 255,\n",
       "         21: 14,\n",
       "         17: 58,\n",
       "         22: 6,\n",
       "         1: 1,\n",
       "         3: 15,\n",
       "         26: 1,\n",
       "         23: 9,\n",
       "         29: 1,\n",
       "         2: 1,\n",
       "         27: 2,\n",
       "         25: 1,\n",
       "         24: 2})"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa = pd.read_csv(\"a/a_train.csv\", names=[0,1,2,3,4,5,6,'label'])\n",
    "Counter(Xa.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4083"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xa.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xa.iloc[:,0:7]\n",
    "y = Xa.iloc[:, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random over-sampling\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_ros, y_ros = ros.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       123\n",
      "           2       0.81      1.00      0.89       141\n",
      "           3       0.35      0.87      0.50       127\n",
      "           4       0.18      0.08      0.11       137\n",
      "           5       0.20      0.02      0.04       135\n",
      "           6       0.00      0.00      0.00       129\n",
      "           7       0.00      0.00      0.00       145\n",
      "           8       0.00      0.00      0.00       142\n",
      "           9       0.00      0.00      0.00       121\n",
      "          10       0.05      0.01      0.01       136\n",
      "          11       0.00      0.00      0.00       125\n",
      "          12       0.00      0.00      0.00       144\n",
      "          13       0.00      0.00      0.00       126\n",
      "          14       0.00      0.00      0.00       143\n",
      "          15       0.00      0.00      0.00       134\n",
      "          16       0.00      0.00      0.00       146\n",
      "          17       0.00      0.00      0.00       133\n",
      "          18       0.00      0.00      0.00       110\n",
      "          19       0.00      0.00      0.00       131\n",
      "          20       0.00      0.00      0.00       131\n",
      "          21       0.04      1.00      0.08       126\n",
      "          22       0.00      0.00      0.00       137\n",
      "          23       0.00      0.00      0.00       125\n",
      "          24       0.00      0.00      0.00       148\n",
      "          25       0.00      0.00      0.00       136\n",
      "          26       0.00      0.00      0.00       146\n",
      "          27       0.00      0.00      0.00       134\n",
      "          29       0.00      0.00      0.00       136\n",
      "\n",
      "    accuracy                           0.14      3747\n",
      "   macro avg       0.09      0.14      0.09      3747\n",
      "weighted avg       0.09      0.14      0.09      3747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\envs\\pytorch15\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSBoost Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       135\n",
      "           2       0.00      0.00      0.00       147\n",
      "           3       0.00      0.00      0.00       153\n",
      "           4       0.00      0.00      0.00       122\n",
      "           5       0.00      0.00      0.00       121\n",
      "           6       0.00      0.00      0.00       145\n",
      "           7       0.06      0.43      0.11       118\n",
      "           8       0.20      0.25      0.23       130\n",
      "           9       0.00      0.00      0.00       138\n",
      "          10       0.00      0.00      0.00       120\n",
      "          11       0.00      0.00      0.00       133\n",
      "          12       0.00      0.00      0.00       141\n",
      "          13       0.00      0.00      0.00       124\n",
      "          14       0.00      0.00      0.00       131\n",
      "          15       0.07      0.85      0.14       135\n",
      "          16       0.00      0.00      0.00       128\n",
      "          17       0.00      0.00      0.00       137\n",
      "          18       0.00      0.00      0.00       142\n",
      "          19       0.00      0.00      0.00       156\n",
      "          20       0.00      0.00      0.00       134\n",
      "          21       0.18      0.33      0.23       129\n",
      "          22       0.00      0.00      0.00       116\n",
      "          23       0.00      0.00      0.00       119\n",
      "          24       0.00      0.00      0.00       129\n",
      "          25       0.33      1.00      0.49       144\n",
      "          26       0.44      1.00      0.61       130\n",
      "          27       0.00      0.00      0.00       147\n",
      "          29       0.00      0.00      0.00       143\n",
      "\n",
      "    accuracy                           0.17      3747\n",
      "   macro avg       0.08      0.17      0.10      3747\n",
      "weighted avg       0.08      0.17      0.10      3747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\envs\\pytorch15\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy Ensemble Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       119\n",
      "           2       0.00      0.00      0.00       144\n",
      "           3       0.07      0.13      0.09       149\n",
      "           4       0.34      0.98      0.50       139\n",
      "           5       0.71      0.11      0.19       139\n",
      "           6       0.41      0.06      0.10       124\n",
      "           7       0.00      0.00      0.00       119\n",
      "           8       0.00      0.00      0.00       151\n",
      "           9       0.00      0.00      0.00       141\n",
      "          10       0.00      0.00      0.00       135\n",
      "          11       0.00      0.00      0.00       139\n",
      "          12       0.00      0.00      0.00       136\n",
      "          13       0.00      0.00      0.00       139\n",
      "          14       0.00      0.00      0.00       118\n",
      "          15       0.00      0.00      0.00       141\n",
      "          16       0.00      0.00      0.00       139\n",
      "          17       0.00      0.00      0.00       125\n",
      "          18       0.00      0.00      0.00       140\n",
      "          19       0.00      0.00      0.00       114\n",
      "          20       0.00      0.00      0.00       129\n",
      "          21       0.00      0.00      0.00       134\n",
      "          22       0.00      0.00      0.00       142\n",
      "          23       0.09      0.12      0.10       139\n",
      "          24       0.00      0.00      0.00       130\n",
      "          25       0.00      0.00      0.00       124\n",
      "          26       0.05      1.00      0.09       139\n",
      "          27       0.00      0.00      0.00       132\n",
      "          29       0.00      0.00      0.00       127\n",
      "\n",
      "    accuracy                           0.09      3747\n",
      "   macro avg       0.06      0.09      0.04      3747\n",
      "weighted avg       0.06      0.09      0.04      3747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\envs\\pytorch15\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Bagging Classifier evalute on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       145\n",
      "           2       1.00      1.00      1.00       143\n",
      "           3       1.00      1.00      1.00       134\n",
      "           4       0.99      1.00      1.00       131\n",
      "           5       0.92      0.99      0.95       131\n",
      "           6       0.75      0.96      0.84       129\n",
      "           7       0.78      0.74      0.76       160\n",
      "           8       0.52      0.46      0.49       134\n",
      "           9       0.25      0.24      0.25       125\n",
      "          10       0.45      0.29      0.35       138\n",
      "          11       0.64      0.51      0.57       150\n",
      "          12       0.78      0.80      0.79       131\n",
      "          13       0.84      0.94      0.89       121\n",
      "          14       0.92      1.00      0.96       139\n",
      "          15       0.95      0.96      0.96       136\n",
      "          16       0.95      1.00      0.97       129\n",
      "          17       0.97      1.00      0.98       131\n",
      "          18       0.95      1.00      0.97       124\n",
      "          19       0.94      1.00      0.97       136\n",
      "          20       0.98      1.00      0.99       120\n",
      "          21       0.98      1.00      0.99       128\n",
      "          22       1.00      1.00      1.00       132\n",
      "          23       1.00      1.00      1.00       141\n",
      "          24       1.00      1.00      1.00       120\n",
      "          25       1.00      1.00      1.00       137\n",
      "          26       1.00      1.00      1.00       129\n",
      "          27       1.00      1.00      1.00       138\n",
      "          29       1.00      1.00      1.00       135\n",
      "\n",
      "    accuracy                           0.89      3747\n",
      "   macro avg       0.88      0.89      0.88      3747\n",
      "weighted avg       0.88      0.89      0.88      3747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brf = balanced_random_forest(X_ros, y_ros, n=20, depth=2, state=9, divide=0.2)\n",
    "rusb = rus_boost(X_ros, y_ros, n=50, lr=1e-2, state=0)\n",
    "eec = easy_ensemble(X_ros, y_ros, n=10)\n",
    "bbc = balanced_bagging(X_ros, y_ros, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Balanced Bagging Classifier to predict on testing set\n",
    "Xa_test = pd.read_csv(\"a/a_test.csv\")\n",
    "X_test = Xa_test.iloc[:,:7]\n",
    "pred = bbc.predict(Xa_test.iloc[:,:7])\n",
    "Xa_test['label'] = pred\n",
    "\n",
    "# Save\n",
    "Xa_test.to_csv(\"a_test_pred.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pytorch15': conda)",
   "language": "python",
   "name": "python361064bitpytorch15conda6dfa5d11f9dc4869915e9696c35b4e03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
